import requests
import json
import pandas as pd
import os
import sys

# ì„¤ì •
LM_STUDIO_BASE_URL = "http://localhost:1234/v1"
HEADERS = {
    "Content-Type": "application/json",
    "Authorization": "Bearer lm-studio" # ë”ë¯¸ API í‚¤
}
CSV_FILE_PATH = "test.csv" # íŒŒì¼ ì…ë ¥ ëª¨ë“œì—ì„œ ì‚¬ìš©í•  CSV íŒŒì¼ ê²½ë¡œ

def get_current_model_name():
    """
    LM Studioì—ì„œ í˜„ì¬ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡ì„ ê°€ì ¸ì™€ ì²« ë²ˆì§¸ ëª¨ë¸ì˜ IDë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    models_url = f"{LM_STUDIO_BASE_URL}/models"
    try:
        response = requests.get(models_url, headers=HEADERS)
        response.raise_for_status()
        models_data = response.json()
        
        if models_data and 'data' in models_data and models_data['data']:
            model_id = models_data['data'][0]['id']
            print(f"âœ… í˜„ì¬ ì‚¬ìš© ì¤‘ì¸ ëª¨ë¸ ID: {model_id}")
            return model_id
        else:
            print("âš ï¸ LM Studio ì„œë²„ì— ë¡œë“œëœ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.")
            return None
            
    except requests.exceptions.ConnectionError:
        print(f"âŒ ì˜¤ë¥˜: LM Studio ì„œë²„ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì„œë²„ ì£¼ì†Œë¥¼ í™•ì¸í•˜ê±°ë‚˜ LM Studioì—ì„œ ì„œë²„ë¥¼ ì‹œì‘í•˜ì„¸ìš”: {LM_STUDIO_BASE_URL}")
        return None
    except requests.exceptions.RequestException as e:
        print(f"âŒ API ìš”ì²­ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None

def chat_completion(model_name, prompt):
    """
    LM Studio ëª¨ë¸ì—ê²Œ ì‘ë‹µì„ ìš”ì²­í•©ë‹ˆë‹¤.
    """
    chat_url = f"{LM_STUDIO_BASE_URL}/chat/completions"
    
    
    # OpenAI Chat Completions API í˜•ì‹ì— ë§ëŠ” ìš”ì²­ í˜ì´ë¡œë“œ
    payload = {
        "model": model_name,
        "messages": [
            {"role": "user", "content": prompt}
        ],
        "temperature": 0.1, # ê°ê´€ì‹ ë¬¸ì œ í’€ì´ë¥¼ ìœ„í•´ ë‚®ì€ ê°’ ì„¤ì •
        "max_tokens": 5122
    }

    try:
        response = requests.post(chat_url, headers=HEADERS, data=json.dumps(payload))
        response.raise_for_status()

        data = response.json()
        
        # ëª¨ë¸ ì‘ë‹µ ì¶”ì¶œ
        if data and 'choices' in data and data['choices']:
            # ì‘ë‹µì—ì„œ ë¶ˆí•„ìš”í•œ ê³µë°±/ì¤„ë°”ê¿ˆ ì œê±°
            return data['choices'][0]['message']['content'].strip()
        else:
            return "ëª¨ë¸ë¡œë¶€í„° ì‘ë‹µì„ ë°›ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."

    except requests.exceptions.RequestException as e:
        return f"âŒ ì±„íŒ… ì‘ë‹µ ìš”ì²­ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}"

## ëª¨ë“œ 1: ì‚¬ìš©ì ì§ì ‘ ì§ˆë¬¸ ëª¨ë“œ
def run_interactive_mode(model_name):
    """
    ì‚¬ìš©ìì˜ ì…ë ¥ì„ ë°›ì•„ ì‹¤ì‹œê°„ìœ¼ë¡œ ëª¨ë¸ì— ì§ˆë¬¸í•˜ê³  ì‘ë‹µì„ ì¶œë ¥í•©ë‹ˆë‹¤.
    """
    print("\n[ëª¨ë“œ 1: ì‚¬ìš©ì ì§ì ‘ ì§ˆë¬¸ ëª¨ë“œ] (ì¢…ë£Œ: 'quit')")
    
    while True:
        user_input = input("ğŸ‘¤ ë‹¹ì‹ : ")
        if user_input.lower() == 'quit':
            break
        
        bot_response = chat_completion(model_name, user_input)
        
        print(f"ğŸ¤– ì±—ë´‡: {bot_response}")

## ëª¨ë“œ 2: íŒŒì¼ ì…ë ¥ ëª¨ë“œ (ì •ë‹µ í™•ì¸ ë° ì •ë‹µë¥  ê³„ì‚° ì¶”ê°€)
def run_file_mode(model_name):
    """
    test.csv íŒŒì¼ì„ ì½ì–´ì™€ ê°ê´€ì‹ ì§ˆë¬¸ì„ ìƒì„±í•˜ê³  ëª¨ë¸ì— ì§ˆì˜í•˜ë©° ì •ë‹µë¥ ì„ ê³„ì‚°í•©ë‹ˆë‹¤.
    """
    print(f"\n[ëª¨ë“œ 2: íŒŒì¼ ì…ë ¥ ëª¨ë“œ] - '{CSV_FILE_PATH}' íŒŒì¼ ì²˜ë¦¬ ì‹œì‘")
    
    if not os.path.exists(CSV_FILE_PATH):
        print(f"âŒ ì˜¤ë¥˜: ì§€ì •ëœ íŒŒì¼ '{CSV_FILE_PATH}'ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê²½ë¡œë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
        return

    try:
        # CSV íŒŒì¼ ë¡œë“œ
        df = pd.read_csv(CSV_FILE_PATH)
        required_columns = ['Question', 'Option 1', 'Option 2', 'Option 3', 'Option 4', 'Answer']
        
        # í•„ìˆ˜ ì¹¼ëŸ¼ í™•ì¸
        if not all(col in df.columns for col in required_columns):
            print(f"âŒ ì˜¤ë¥˜: CSV íŒŒì¼ì— í•„ìš”í•œ ì¹¼ëŸ¼({', '.join(required_columns)}) ì¤‘ ì¼ë¶€ê°€ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤.")
            return

        results = []
        correct_count = 0
        total_questions = len(df)
        
        for index, row in df.iterrows():
            question = row['Question']
            options = [
                row['Option 1'], row['Option 2'], row['Option 3'], row['Option 4']
            ]
            correct_answer = str(row['Answer']).strip() # AnswerëŠ” ë¬¸ìì—´ë¡œ ì²˜ë¦¬í•˜ê³  ê³µë°± ì œê±°

            # ì§ˆë¬¸ ë° ì„ íƒì§€ í¬ë§·íŒ…
            formatted_options = "\n".join([f"{i+1}. {opt}" for i, opt in enumerate(options)])
            full_prompt = (
                f"ë‹¤ìŒ ë¬¸ì œì— ëŒ€í•´ ê°€ì¥ ì ì ˆí•œ ì„ íƒì§€ ë²ˆí˜¸(1, 2, 3, 4 ì¤‘ í•˜ë‚˜)ë§Œ ì¶œë ¥í•˜ì„¸ìš”. "
                f"ë‹¤ë¥¸ ì„¤ëª…ì€ í•„ìš” ì—†ìŠµë‹ˆë‹¤.\n\n"
                f"ë¬¸ì œ: {question}\n{formatted_options}"
            )

            print(f"\n--- [ë¬¸ì œ {index+1}/{total_questions}] ---")
            print(f"ì§ˆë¬¸: {question}")
            
            # ëª¨ë¸ ì§ˆì˜
            model_answer = chat_completion(model_name, full_prompt)
            model_answer_stripped = model_answer.strip()
            
            # ì •ë‹µ í™•ì¸
            is_correct = (model_answer_stripped == correct_answer)
            if is_correct:
                correct_count += 1
                result_text = "O"
            else:
                result_text = "X"

            print(f"ì •ë‹µ: {correct_answer}, ëª¨ë¸ ì‘ë‹µ: {model_answer_stripped}, ê²°ê³¼: {result_text}")
            
            # ê²°ê³¼ ì €ì¥
            results.append({
                'Question': question,
                'option 1': row['Option 1'],
                'option 2': row['Option 2'],
                'option 3': row['Option 3'],
                'option 4': row['Option 4'],
                'Answer': correct_answer,
                'Model Response': model_answer,
                'Is Correct (O/X)': result_text
            })

        # ì •ë‹µë¥  ê³„ì‚°
        accuracy = (correct_count / total_questions) * 100 if total_questions > 0 else 0
        
        # ê²°ê³¼ë¥¼ DataFrameìœ¼ë¡œ ë³€í™˜
        results_df = pd.DataFrame(results)
        
        # ìµœì¢… ì‘ë‹µ íŒŒì¼ì— ì •ë‹µë¥  ë° ëª¨ë¸ ì •ë³´ ì¶”ê°€
        footer_data = {
            'Question': [""],
            'option 1': [""],
            'option 2': [""],
            'option 3': [""],
            'option 4': [""],
            'Answer': [""],
            'Model Response': [f"ì •ë‹µë¥ : {accuracy:.2f}%"],
            'Is Correct (O/X)': [f"ì‚¬ìš© ëª¨ë¸: {model_name}"]
        }
        footer_df = pd.DataFrame(footer_data)
        
        # ì „ì²´ ë°ì´í„°í”„ë ˆì„ ê²°í•©
        final_df = pd.concat([results_df, footer_df], ignore_index=True)
        
        # ê²°ê³¼ë¥¼ ìƒˆë¡œìš´ CSV íŒŒì¼ë¡œ ì €ì¥
        output_file = "model_responses.csv"
        final_df.to_csv(output_file, index=False, encoding='utf-8-sig')
        
        print(f"\n==============================================")
        print(f"âœ… íŒŒì¼ ì…ë ¥ ëª¨ë“œ ì™„ë£Œ.")
        print(f"ì´ ë¬¸ì œ ìˆ˜: {total_questions}ê°œ, ì •ë‹µ ìˆ˜: {correct_count}ê°œ")
        print(f"â­ ìµœì¢… ì •ë‹µë¥ : {accuracy:.2f}%")
        print(f"ê²°ê³¼ê°€ '{output_file}'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        print(f"==============================================")

    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜: íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ë°œìƒ: {e}")

def main():
    print("ğŸ¤– LM Studio Chatbot ì‹œì‘")
    
    # 1. ëª¨ë¸ ì´ë¦„ í™•ì¸
    current_model = get_current_model_name()
    
    if not current_model:
        print("LM Studio ëª¨ë¸ ì„œë²„ì— ì—°ê²°í•  ìˆ˜ ì—†ì–´ í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
        return

    # 2. ì‹¤í–‰ ëª¨ë“œ ì„ íƒ
    print("\n--- ì‹¤í–‰ ëª¨ë“œ ì„ íƒ ---")
    print("1. ì‚¬ìš©ì ì§ì ‘ ì§ˆë¬¸ ëª¨ë“œ")
    print("2. íŒŒì¼ ì…ë ¥ ëª¨ë“œ (test.csv)")
    
    while True:
        mode = input("ëª¨ë“œ ë²ˆí˜¸ë¥¼ ì…ë ¥í•˜ì„¸ìš” (1 ë˜ëŠ” 2): ")
        if mode == '1':
            run_interactive_mode(current_model)
            break
        elif mode == '2':
            run_file_mode(current_model)
            break
        else:
            print("ì˜ëª»ëœ ì…ë ¥ì…ë‹ˆë‹¤. 1 ë˜ëŠ” 2ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            
    print("ğŸ‘‹ LM Studio ì±—ë´‡ í”„ë¡œê·¸ë¨ì´ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")


if __name__ == "__main__":
    main()